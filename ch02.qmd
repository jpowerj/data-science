---
format:
  html:
    include-in-header: {"text": "<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css'><link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css' integrity='sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==' crossorigin='anonymous' referrerpolicy='no-referrer' />"}
metadata-files: 
  - "_bookdown.globals.yml"
---

# Data Science Workflow

{{< include _draft-notice.qmd >}}

{{< include _r.globals.qmd >}}
{{< include _gg.globals.qmd >}}

<!-- <a href="./ch02.slides.html" target="_blank" class="h3">Open slides for chapter in new window &rarr;</a>

```{=html}
<iframe src="./ch02.slides.html" width="100%" height="400"></iframe>
``` -->

At the end of the previous chapter we learned how to install `R` and Python. **Both** of these languages are central pieces of the data scientist's toolkit, so throughout this book we will aim to build your skills in both, while highlighting tasks that may be easier to carry out in one language relative to the other.[^js] Therefore, while we will mark sections with <i class="fa-brands fa-python"></i> if they contain details specific to Python and with <i class="fa-brands fa-r-project"></i> if they contain details specific to `R`, throughout the book we will include both `R` and Python versions of each main topic's code examples, separated using tabs like:

::: {.panel-tabset}

## Python

```{python}
#| label: py-tabset-example
#| code-fold: show
import pandas as pd
import numpy as np
import seaborn as sns
rng = np.random.default_rng(seed=1948)
x = rng.normal(0, 1, 10)
y = rng.normal(0, 1, 10)
df = pd.DataFrame({'x': x, 'y': y})
sns.scatterplot(x='x', y='y', data=df)
```

## R

```{r}
#| label: r-tabset-example
#| code-fold: show
library(ggplot2)
library(tibble)
x <- rnorm(10, 0, 1)
y <- rnorm(10, 0, 1)
df <- tibble(x=x, y=y)
ggplot(df, aes(x=x, y=y)) +
  geom_point(size = g_pointsize) +
  dsan_theme("full")
```

:::

[^js]: A third language that is increasingly being used by data scientists is JavaScript/TypeScript, which is especially nice to know since it is the canonical language for **web development** as well. For examples of beautiful data visualizations using the d3.js library, see <a href="https://d3-graph-gallery.com/" target="_blank">The D3 Graph Gallery</a>.

## First Things First: Shell Commands

Oftentimes, given the association of data science with programming languages, your first instinct when starting a data science project will be to create an `R` or Python file. For the sake of building effective data science habits, however, you should ask yourself if the task you're trying to accomplish could be done more simply using shell commands. @jurafsky_speech_2023, for example, one of the most widely-used Natural Language Processing textbooks, introduces the concept of text normalization using Unix commands rather than Python or `R`. Demonstrating how Unix can quickly (usually far more quickly than `R` or Python, for simpler tasks like this) process text corpora, they take a text file `sh.txt` containing the complete works of Shakespeare and use the following Unix command

```bash
tr -sc 'A-Za-z' '\n' < sh.txt | tr A-Z a-z | sort | uniq -c | sort -n -r
```

to discover the ten most frequently-occurring words across Shakespeare's works:

```
27378 the
26084 and
22538 i
19771 to
17481 of
14725 a
13826 you
12489 my
11318 that
11112 in
```

In the case of data science in general, simple operations like **creating, moving, and copying files**, **downloading files from the internet**, and **searching for particular phrases or expressions** across your entire disk or within a particular directory are all tasks that can be carried out easily and effectively using a small set of Unix commands.

## `R` and Python for Data Science

When it comes to learning the basics of `R`, Python, or any other programming language, we believe that there's no need for us to reinvent the wheel---there are thousands of incredible resources available for free on the internet that can do a better job of teaching the fundamentals of these languages better than we ever could. If you don't feel comfortable in terms of programming experience, we recommend the following resources in particular (which you can work through and then return to the book!):

* <a href="https://www.datacamp.com/" target="_blank">DataCamp</a>
* <a href="https://www.codecademy.com/" target="_blank">Codecademy</a>

Whether or not you have this background knowledge, don't worry! We will still work to make sure that we explain new concepts with as little technical jargon as possible throughout.

## Python: Pandas and NumPy

While `R` has a range of libraries that are helpful for reading, manipulating, and analyzing data, in Python two particular libraries stand above the rest: Pandas and NumPy. After installing them on the command-line using

```bash
pip install pandas
pip install numpy
```

you'll be able to import and start using them by including the following at the top of your code:

```{python}
#| label: pandas-import
import pandas as pd
import numpy as np
```

Note that the syntax here, `import <x> as <y>`, tells Python that you want to import the library whose full name is `<x>`, but that in your code you'd like to **reference** this imported library using the shorthand `<y>`.

::: {.callout-tip title="Importing Pandas and NumPy"}

It is standard practice in data science to use this shorthand---`pd` to refer to `pandas` and `np` to refer to `numpy`---when importing the two libraries. This practice will help immensely when e.g. searching the web for errors in the functions you're using (since those functions will be written as `pd.<function>`)

```python
import pandas as pd
import numpy as np
```

:::

Once you have imported these libraries, a standard data science workflow for opening a data file and viewing its contents looks like:

```{python}
#| code-fold: show
#| label: load-csv
df = pd.read_csv("./assets/data/ch02/mydata.csv")
df.head()
```

We can then perform an operation on our data, like dropping the first row, and use `head()` again to make sure the code did what we expected it to do to our DataFrame:

```{python}
#| label: remove-first-row
df = df.iloc[1:].copy()
df.head()
```

### DataFrames vs. Views of DataFrames

Probably the most frequent source of errors, over all of the data science couses we've taught, has been Pandas' distinction between a DataFrame itself and a **view** of a DataFrame. There is a good reason for the distinction, but it is typically a baffling concept for anyone just starting to work with DataFrames. To understand this distinction, we first need to quickly look at the structure of how **objects** are stored in memory (this is how storage works in general---in Python, `R`, or any other programming language---so it's useful knowledge regardless of what particular corner of the data science world you occupy!).

### The Stack and the Heap

Let's look at what happens, in the computer's memory, when we run the following code:

```{python}
#| code-fold: show
#| label: py-memory-example
import datetime
country_df = pd.read_csv("./assets/data/ch02/country_pop.csv")
pop_col = country_df['pop']
num_rows = len(country_df)
filled = all(~pd.isna(country_df))
alg_row = country_df.loc[country_df['name'] == "Algeria"]
num_cols = len(country_df.columns)
username = "Jeff"
cur_date = datetime.datetime.now()
i = 0
j = None
z = 314
```

And let's look at the values Python prints out when we ask it to print some of these variables. First, the whole DataFrame, `country_df`:

```{python}
#| code-fold: show
#| label: print-whole-df
country_df
```

Next, `pop_col`:

```{python}
#| code-fold: show
#| label: print-df-column
pop_col
```

How about `alg_row`?

```{python}
#| code-fold: show
#| label: print-df-row
alg_row
```

These three variables `country_df`, `pop_col`, and `alg_row` may seem like they are three separate, entirely distinct entities in the computer's memory. After all, we gave them three different names, right? Let's look at how this situation would be represented **in the computer's memory**, however:

```{dot, out.width="20%"}
#| fig-align: center
digraph g {
    rankdir=LR
    concentrate=True
	subgraph clusterG0 {
		label="Memory (After Code Execution)"
		subgraph clusterG1 {
				label="Stack"
                stvars[label = "{{<name0>country_df|<name1>pop_col|num_rows|filled|alg_row|num_cols|username|cur_date|i|j|z}|{<addr0>0x03a80afc|<addr1>0x10ba8|<f1>13|<f2>TRUE|<f4>0xf7fc4380|<f5>2|<f6>0xf7fc43e0|<f7>8ec3d9889|<f8>0|<f9>NULL|<f10>314}}",shape = "record",fontname="Courier"]
		}
		subgraph clusterG2 {
				label="Heap"
                subgraph clusterG20 {
                    #label="DataFrame object"
                    label=""
                    nodesep=0.002
                    h0[label="<d0>DataFrame object",penwidth=0,shape="record"]
                    h1[label="{{<g0>|0|<g2>1|<g3>2}|{<g1>name|Albania|Algeria|<g4>Angola}|{<g5>pop|2.8|44.2|34.5}}",shape="record"]
                }
    	    h3 [label="\"Jeff\"",fontname="Courier",penwidth=0]
	        h4 [label="Date[2023-07-22]",fontname="Courier",penwidth=0]
		}
        "stvars":addr0 -> "h0":d0[constraint=True]
        "stvars":addr1 -> "h1":g5[style="dashed",constraint=True] #,xlabel="View"]
        "stvars":f4 -> "h1":g2[style="dashed",constraint=True] #,xlabel="View"]
        "stvars":f6 -> h3
        "stvars":f7 -> h4
	}
}
```

The Python interpreter did something smart: when we asked it to create a variable called `pop_col` containing just that column of the full DataFrame, and a variable called `alg_row` for just one row of the full DataFrame, it knew that it didn't have to construct two entirely new objects in its memory. Instead, since it knows that `country_df` contains all of the data that `pop_col` and `alg_row` are subsetting, in its box for `pop_col` it just stored a **pointer**, pointing to that particular column, rather than an entirely new object built from scratch (in other words, an object for which we'd have to ask the computer to allocate more storage space for us). And similarly, its box for `alg_row` just contains a pointer to that particular row.

Disaster strikes, however, if we modify `country_df` without realizing that this will therefore also modify `pop_col` and `alg_row`, since these simply point to specific pieces of `country_df`.

A straightforward and effective way to avoid this disaster is by thinking about whether or not you need to **persist** a particular variable in memory, and whether you'd like to manipulate it **separately from** the main DataFrame you're working with. So in our case, if we knew that we wanted to do something to `pop_col` (say, rescale all the populations to be in units of people rather than millions of people), we could save ourselves a huge headache by writing

```{python}
#| code-fold: show
#| label: pandas-copy
pop_col = country_df['pop'].copy()
```

Now that we've told Python that we want a **copy** of the column, not just a pointer to a piece of `country_df`, we can do whatever we want to `country_df` and/or `pop_col` without having to worry about whether changes to one will affect the other.

Most commonly, however, this issue comes about in the following way: when we ask Pandas to perform some **operation** on our DataFrame, typically we glance at the resulting output from the code, see that it looks correct, and move on. You need to train your brain to intervene when you fall into this habit! Instead, you also need to check that the operation was **permanent**---i.e., that it was performed **in-place** rather than **as a copy**. To see what we mean, let's try sorting the values in `country_df` by population, instead of alphabetically:

```{python}
#| label: pandas-sort-temporary
country_df.sort_values(by='pop')
```

All good, right? No! Stop yourself here! Our brains naturally want to move on once we've visually observed the above output: cool, we're good, I see it and it's sorted, onto the next task. But the issue is that, **by default**, Pandas shows us the result of an operation by returning a **copy** of the original DataFrame with the operation performed, **not** the original DataFrame itself. Basically, you can think of this like when you make a change to some file and your computer asks you "would you like to save these changes?" **By default, Pandas is showing you the changes, and it is your job to SAVE these changes** if you want to use the post-operation DataFrame later on in your code. If you don't, then despite the output of the above code *looking* correct, the DataFrame will revert to its previous, non-sorted state from the next line of code onwards:

```{python}
#| label: pandas-not-sorted
country_df
```

Like the `.copy()` function above, the most straightforward way to avoid this issue is by using the argument that can be passed to most Pandas functions: `inplace`. As discussed above, the default value is `False`: the changes are **not** made to the original DataFrame, but to a copy of it. If you specify `inplace=True`, however, your problem is solved: this tells Pandas that you'd like the operation to be **permanent**, so that e.g., using our `sort_values()` example from above, `country_df` will now be sorted by population when subsequent lines of code are executed! Let's look at the difference, examining not the output of `sort_values()` itself but the state of the DataFrame `country_df` after `sort_values()` has been run with the `inplace=True` argument:

```{python}
country_df.sort_values(by='pop', inplace=True)
country_df
```

Since this is the behavior most students/data scientists intuitively expect anyways, you will eventually get in the habit of adding `inplace=True` to most of your calls to Pandas functions, but it's good to take a moment to think about this---for example, imagining some cases where you **wouldn't** want Pandas to perform the operation in-place.

### Manipulating a DataFrame

```{python}
#| code-fold: show
country_df['pop'] = country_df['pop'] * 2
country_df['name'] = country_df['name'].str.lower()
country_df
```

To understand why these two operations did **not** require us to use the `inplace=True` argument we discussed in the previous section, it's important to note how the `=` operator works in Python:

::: {.callout-tip title="The Assignment Operator"}

One good thing about `R` is the fact that it uses the syntax `my_var <- value` to represent assigning `value` to the variable `my_var`. Python, on the other hand, uses the single equals sign, like `my_var = value`. Thus, when using Python, it's important to keep in mind the different uses of the equals sign:

* `=` is the **assignment operator**: it assigns the value on its right-hand side to the variable name on its left hand side
* `==` is the **equality** operator: it checks whether the value before it is equal to the value after it, returning `True` if they're equal and `False` otherwise.

:::

Keep in mind that this assignment operator is evaluated from **right to left**: when we tell Python e.g. `x = y + 3`, we are telling it, "first add `3` to the value of the variable `y`, then store the result of that addition as the variable `x`." Therefore, when we write something like `x = x + 3`, that may be confusing at first glance since `x` appears on both the left and right sides, keeping this order in mind helps clarify what's going on: Python **first** adds `3` to the current value of the variable `x`, **then** stores the result of this addition as the variable `x` (thus overwriting the original value that it used when computing the addition).

So, in the case of the two operations we performed on `country_df` above---multiplying the values in the `pop` column by 2 and lowercasing all of the values in the `name` column---we don't need to specify `inplace=True` anywhere since we're **explicitly** overwriting the values in the columns using the `=` operator.

Now, looking at the details of how we performed these operations, note the two ways we've now seen to access or update **rows** and **columns** of a DataFrame:

::: {.callout-tip title="Pandas Syntax: Accessing Columns"}

In Pandas, accessing **columns** is the "default" way to access pieces of a DataFrame, so that all you need to do is specify the name of the DataFrame you want to access a column from, and then include the name of the column surrounded by **square brackets**:

```python
df['col_name']
```

:::

::: {.callout-tip title="Pandas Syntax: Accessing Rows"}

Unlike the default column-selection operator, where we just use `[]` to specify the column we want, accessing **rows** in Pandas requires us to use a special `.loc[]` operator, providing a **boolean expression** within the square brackets which it will use to select only the rows for which the boolean expression evaluates to `True`. For example, to select only the rows of our `country_df` DataFrame where the `name` value is `"Algeria"`, we write

```python
country_df.loc[country_df['name'] == "algeria"]
```

Take a minute to look at how exactly this works, early on, and it will save you lots of headaches in the long run: zooming in on the expression inside the square brackets after `.loc`, we see

```python
country_df['name'] == "algeria"
```

This expression, on its own, goes through each row of `country_df` and checks if its `name` value is equal to `"algeria"`. If it is, the expression stores a value of `True` at that row's index, and `False` otherwise. Therefore, since the full `name` column consists of the values `["albania","algeria","angola"]`, the result of the above boolean expression will be `[False, False, True]`. Our original, full expression:

```python
country_df[country_df['name'] == "algeria"]
```

will therefore know (by looking at the `[False, False, True]` result of the expression inside the square brackets after `.loc`) to only include the third row, giving us the following result:

```{python}
#| label: pandas-select-row
country_df.loc[country_df['name'] == "algeria"]
```

:::

## `R`: `readr`, Tibbles, and `dplyr`

