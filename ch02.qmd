---
format:
  html:
    include-in-header: {"text": "<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css'><link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css' integrity='sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==' crossorigin='anonymous' referrerpolicy='no-referrer' />"}
metadata-files: 
  - "_bookdown.globals.yml"
---

# Data Science Workflow

{{< include _draft-notice.qmd >}}

<!-- <a href="./ch02.slides.html" target="_blank" class="h3">Open slides for chapter in new window &rarr;</a>

```{=html}
<iframe src="./ch02.slides.html" width="100%" height="400"></iframe>
``` -->

At the end of the previous chapter we learned how to install `R` and Python. **Both** of these languages are central pieces of the data scientist's toolkit, so throughout this book we will aim to build your skills in both, while highlighting tasks that may be easier to carry out in one language relative to the other.[^js]

[^js]: A third language that is increasingly being used by data scientists is JavaScript/TypeScript, which is especially nice to know since it is the canonical language for **web development** as well. For examples of beautiful data visualizations using the d3.js library, see <a href="https://d3-graph-gallery.com/" target="_blank">The D3 Graph Gallery</a>.

## First Things First: Shell Commands

Oftentimes, given the association of data science with programming languages, your first instinct when starting a data science project will be to create an `R` or Python file. For the sake of building effective data science habits, however, you should ask yourself if the task you're trying to accomplish could be done more simply using shell commands. @jurafsky_speech_2023, for example, one of the most widely-used Natural Language Processing textbooks, introduces the concept of text normalization using Unix commands rather than Python or `R`. Demonstrating how Unix can quickly (usually far more quickly than `R` or Python, for simpler tasks like this) process text corpora, they take a text file `sh.txt` containing the complete works of Shakespeare and use the following Unix command

```bash
tr -sc 'A-Za-z' '\n' < sh.txt | tr A-Z a-z | sort | uniq -c | sort -n -r
```

to discover the ten most frequently-occurring words across Shakespeare's works:

```
27378 the
26084 and
22538 i
19771 to
17481 of
14725 a
13826 you
12489 my
11318 that
11112 in
```

In the case of data science in general, simple operations like **creating, moving, and copying files**, **downloading files from the internet**, and **searching for particular phrases or expressions** across your entire disk or within a particular directory are all tasks that can be carried out easily and effectively using a small set of Unix commands.

## `R` and Python for Data Science

When it comes to learning the basics of `R`, Python, or any other programming language, we believe that there's no need for us to reinvent the wheel---there are thousands of incredible resources available for free on the internet that can do a better job of teaching the fundamentals of these languages better than we ever could. If you don't feel comfortable in terms of programming experience, we recommend the following resources in particular (which you can work through and then return to the book!):

* <a href="https://www.datacamp.com/" target="_blank">DataCamp</a>
* <a href="https://www.codecademy.com/" target="_blank">Codecademy</a>

Whether or not you have this background knowledge, don't worry! We will still work to make sure that we explain new concepts with as little technical jargon as possible throughout.

## Pandas and NumPy

While `R` has a range of libraries that are helpful for reading, manipulating, and analyzing data, in Python two particular libraries stand above the rest: Pandas and NumPy. After installing them on the command-line using

```bash
pip install pandas
pip install numpy
```

you'll be able to import and start using them by including the following at the top of your code:

```{python}
import pandas as pd
import numpy as np
```

Note that the syntax here, `import <x> as <y>`, tells Python that you want to import the library whose full name is `<x>`, but that in your code you'd like to **reference** this imported library using the shorthand `<y>`.

::: {.callout-tip title="Importing Pandas and NumPy"}

It is standard practice in data science to use this shorthand---`pd` to refer to `pandas` and `np` to refer to `numpy`---when importing the two libraries. This practice will help immensely when e.g. searching the web for errors in the functions you're using (since those functions will be written as `pd.<function>`)

```python
import pandas as pd
import numpy as np
```

:::

Once you have imported these libraries, a standard data science workflow for opening a data file and viewing its contents looks like:

```{python}
#| code-fold: show
df = pd.read_csv("./assets/data/ch02/mydata.csv")
df.head()
```

We can then perform an operation on our data, like dropping the first row, and use `head()` again to make sure the code did what we expected it to do to our DataFrame:

```{python}
df = df.iloc[1:].copy()
df.head()
```

## DataFrames vs. Views of DataFrames

Probably the most frequent source of errors, over all of the data science couses we've taught, has been Pandas' distinction between a DataFrame itself and a **view** of a DataFrame. There is a good reason for the distinction, but it is typically a baffling concept for anyone just starting to work with DataFrames. To understand this distinction, we first need to quickly look at the structure of how **objects** are stored in memory (this is how storage works in general---in Python, `R`, or any other programming language---so it's useful knowledge regardless of what particular corner of the data science world you occupy!).

### The Stack and the Heap

Let's look at what happens, in the computer's memory, when we run the following code:

```{python}
#| code-fold: show
import datetime
country_df = pd.read_csv("./assets/data/ch02/country_pop.csv")
pop_col = country_df['pop']
num_rows = len(country_df)
filled = all(~pd.isna(country_df))
alg_row = country_df.loc[country_df['name'] == "Algeria"]
num_cols = len(country_df.columns)
username = "Jeff"
cur_date = datetime.datetime.now()
i = 0
j = None
z = 314
```

And let's look at the values Python prints out when we ask it to print some of these variables. First, the whole DataFrame, `country_df`:

```{python}
#| code-fold: show
country_df
```

Next, `pop_col`:

```{python}
#| code-fold: show
pop_col
```

How about `alg_row`?

```{python}
#| code-fold: show
alg_row
```

These three variables `country_df`, `pop_col`, and `alg_row` may seem like they are three separate, entirely distinct entities in the computer's memory. After all, we gave them three different names, right? Let's look at how this situation would be represented **in the computer's memory**, however:

```{dot, out.width="20%"}
#| fig-align: center
digraph g {
    rankdir=LR
    concentrate=True
	subgraph clusterG0 {
		label="Memory (After Code Execution)"
		subgraph clusterG1 {
				label="Stack"
                stvars[label = "{{<name0>country_df|<name1>pop_col|num_rows|filled|alg_row|num_cols|username|cur_date|i|j|z}|{<addr0>0x03a80afc|<addr1>0x10ba8|<f1>13|<f2>TRUE|<f4>0xf7fc4380|<f5>2|<f6>0xf7fc43e0|<f7>8ec3d9889|<f8>0|<f9>NULL|<f10>314}}",shape = "record",fontname="Courier"]
		}
		subgraph clusterG2 {
				label="Heap"
                subgraph clusterG20 {
                    #label="DataFrame object"
                    label=""
                    nodesep=0.002
                    h0[label="<d0>DataFrame object",penwidth=0,shape="record"]
                    h1[label="{{<g0>|0|<g2>1|<g3>2}|{<g1>name|Albania|Algeria|<g4>Angola}|{<g5>pop|2.8|44.2|34.5}}",shape="record"]
                }
    	    h3 [label="\"Jeff\"",fontname="Courier",penwidth=0]
	        h4 [label="Date[2023-07-22]",fontname="Courier",penwidth=0]
		}
        "stvars":addr0 -> "h0":d0[constraint=True]
        "stvars":addr1 -> "h1":g5[style="dashed",constraint=True] #,xlabel="View"]
        "stvars":f4 -> "h1":g2[style="dashed",constraint=True] #,xlabel="View"]
        "stvars":f6 -> h3
        "stvars":f7 -> h4
	}
}
```

The Python interpreter did something smart: when we asked it to create a variable called `pop_col` containing just that column of the full DataFrame, and a variable called `alg_row` for just one row of the full DataFrame, it knew that it didn't have to construct two entirely new objects in its memory. Instead, since it knows that `country_df` contains all of the data that `pop_col` and `alg_row` are subsetting, in its box for `pop_col` it just stored a **pointer**, pointing to that particular column, rather than an entirely new object built from scratch (in other words, an object for which we'd have to ask the computer to allocate more storage space for us). And similarly, its box for `alg_row` just contains a pointer to that particular row.

Disaster strikes, however, if we modify `country_df` without realizing that this will therefore also modify `pop_col` and `alg_row`, since these simply point to specific pieces of `country_df`.

A straightforward and effective way to avoid this disaster is by thinking about whether or not you need to **persist** a particular variable in memory, and whether you'd like to manipulate it **separately from** the main DataFrame you're working with. So in our case, if we knew that we wanted to do something to `pop_col` (say, rescale all the populations to be in units of people rather than millions of people), we could save ourselves a huge headache by writing

```{python}
pop_col = country_df['pop'].copy()
```

Now that we've told Python that we want a **copy** of the column, not just a pointer to a piece of `country_df`, we can do whatever we want to `country_df` and/or `pop_col` without having to worry about whether changes to one will affect the other.

Most commonly, however, this issue comes about in the following way: when we ask Pandas to perform some **operation** on our DataFrame, typically we glance at the resulting output from the code, see that it looks correct, and move on. You need to train your brain to intervene when you fall into this habit! Instead, you also need to check that the operation was **permanent**---i.e., that it was performed **in-place** rather than **as a copy**. To see what we mean, let's try sorting the values in `country_df` by population, instead of alphabetically:

```{python}
country_df.sort_values(by='pop')
```

All good, right? No! Stop yourself here! Our brains naturally want to move on once we've visually observed the above output: cool, we're good, I see it and it's sorted, onto the next task. But the issue is that, **by default**, Pandas shows us the result of an operation by returning a **copy** of the original DataFrame with the operation performed, **not** the original DataFrame itself. Basically, you can think of this like when you make a change to some file and your computer asks you "would you like to save these changes?" **By default, Pandas is showing you the changes, and it is your job to SAVE these changes** if you want to use the post-operation DataFrame later on in your code.

Like the `.copy()` function above, the most straightforward way to avoid this issue is by using the argument that is included in most Pandas functions: `inplace`. As discussed above, the default value is `False`: the changes are **not** made to the original DataFrame, but to a copy of it. If you specify `inplace=True`, however, your problem is solved: this tells Pandas that you'd like the operation to be **permanent**, so that e.g., using our `sort_values()` example from above, `country_df` will now be sorted by population when subsequent lines of code are executed! Since this is the behavior most students/data scientists intuitively expect anyways, you will eventually get in the habit of adding `inplace=True` to most of your calls to Pandas functions, but it's good to take a moment to think about this---for example, imagining some cases where you **wouldn't** want Pandas to perform the operation in-place.

## Manipulating a DataFrame

```{python}
#| code-fold: show
country_df['pop'] = country_df['pop'] * 2
country_df['name'] = country_df['name'].str.lower()
country_df
```